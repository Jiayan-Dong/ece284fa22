{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "agreed-korean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=1, bias=False)\n",
      ")\n",
      "[Parameter containing:\n",
      "tensor([[ 1., -1.]], requires_grad=True)]\n",
      "Epoch 0 - loss: 51.35333251953125\n",
      "Epoch 0 - loss: 161.3751983642578\n",
      "Epoch 1 - loss: 13.197955131530762\n",
      "Epoch 1 - loss: 309.8718566894531\n",
      "Epoch 2 - loss: 5.068889617919922\n",
      "Epoch 2 - loss: 228.3203582763672\n",
      "Epoch 3 - loss: 1.5907636880874634\n",
      "Epoch 3 - loss: 131.41429138183594\n",
      "Epoch 4 - loss: 0.9464332461357117\n",
      "Epoch 4 - loss: 65.9544677734375\n",
      "Epoch 5 - loss: 0.3404666483402252\n",
      "Epoch 5 - loss: 32.52096939086914\n",
      "Epoch 6 - loss: 0.2910836338996887\n",
      "Epoch 6 - loss: 15.076024055480957\n",
      "Epoch 7 - loss: 0.13179464638233185\n",
      "Epoch 7 - loss: 7.410629749298096\n",
      "Epoch 8 - loss: 0.1330122947692871\n",
      "Epoch 8 - loss: 3.463763952255249\n",
      "Epoch 9 - loss: 0.07817937433719635\n",
      "Epoch 9 - loss: 1.8572813272476196\n",
      "Epoch 10 - loss: 0.077824167907238\n",
      "Epoch 10 - loss: 0.9575405120849609\n",
      "Epoch 11 - loss: 0.05442333221435547\n",
      "Epoch 11 - loss: 0.611615002155304\n",
      "Epoch 12 - loss: 0.05114321783185005\n",
      "Epoch 12 - loss: 0.3795599043369293\n",
      "Epoch 13 - loss: 0.03923533484339714\n",
      "Epoch 13 - loss: 0.2888394594192505\n",
      "Epoch 14 - loss: 0.03525201976299286\n",
      "Epoch 14 - loss: 0.2114068865776062\n",
      "Epoch 15 - loss: 0.02834402583539486\n",
      "Epoch 15 - loss: 0.175299271941185\n",
      "Epoch 16 - loss: 0.024778151884675026\n",
      "Epoch 16 - loss: 0.13967905938625336\n",
      "Epoch 17 - loss: 0.02040475234389305\n",
      "Epoch 17 - loss: 0.1185436025261879\n",
      "Epoch 18 - loss: 0.017563996836543083\n",
      "Epoch 18 - loss: 0.09776931256055832\n",
      "Epoch 19 - loss: 0.014644068665802479\n",
      "Epoch 19 - loss: 0.08317775279283524\n",
      "Epoch 20 - loss: 0.012499206699430943\n",
      "Epoch 20 - loss: 0.06954427808523178\n",
      "Epoch 21 - loss: 0.010488905012607574\n",
      "Epoch 21 - loss: 0.059058498591184616\n",
      "Epoch 22 - loss: 0.008912012912333012\n",
      "Epoch 22 - loss: 0.049662183970212936\n",
      "Epoch 23 - loss: 0.007504073902964592\n",
      "Epoch 23 - loss: 0.04209618642926216\n",
      "Epoch 24 - loss: 0.006360463798046112\n",
      "Epoch 24 - loss: 0.035491038113832474\n",
      "Epoch 25 - loss: 0.00536522688344121\n",
      "Epoch 25 - loss: 0.03004707582294941\n",
      "Epoch 26 - loss: 0.004541634116321802\n",
      "Epoch 26 - loss: 0.025363972410559654\n",
      "Epoch 27 - loss: 0.0038346864748746157\n",
      "Epoch 27 - loss: 0.021457763388752937\n",
      "Epoch 28 - loss: 0.0032438833732157946\n",
      "Epoch 28 - loss: 0.018124844878911972\n",
      "Epoch 29 - loss: 0.002740307943895459\n",
      "Epoch 29 - loss: 0.015327274799346924\n",
      "Epoch 30 - loss: 0.002317182021215558\n",
      "Epoch 30 - loss: 0.012950780801475048\n",
      "Epoch 31 - loss: 0.001958013279363513\n",
      "Epoch 31 - loss: 0.01094941794872284\n",
      "Epoch 32 - loss: 0.0016553712775930762\n",
      "Epoch 32 - loss: 0.009253262542188168\n",
      "Epoch 33 - loss: 0.0013989811995998025\n",
      "Epoch 33 - loss: 0.007822349667549133\n",
      "Epoch 34 - loss: 0.001182597130537033\n",
      "Epoch 34 - loss: 0.006611193064600229\n",
      "Epoch 35 - loss: 0.0009995249565690756\n",
      "Epoch 35 - loss: 0.0055884369648993015\n",
      "Epoch 36 - loss: 0.0008449076558463275\n",
      "Epoch 36 - loss: 0.004723407793790102\n",
      "Epoch 37 - loss: 0.0007141027599573135\n",
      "Epoch 37 - loss: 0.003992607817053795\n",
      "Epoch 38 - loss: 0.0006036210106685758\n",
      "Epoch 38 - loss: 0.0033747151028364897\n",
      "Epoch 39 - loss: 0.0005102181457914412\n",
      "Epoch 39 - loss: 0.0028525011148303747\n",
      "Epoch 40 - loss: 0.0004312471719458699\n",
      "Epoch 40 - loss: 0.0024110160302370787\n",
      "Epoch 41 - loss: 0.00036450536572374403\n",
      "Epoch 41 - loss: 0.0020379337947815657\n",
      "Epoch 42 - loss: 0.00030809835880063474\n",
      "Epoch 42 - loss: 0.0017225383780896664\n",
      "Epoch 43 - loss: 0.0002604268374852836\n",
      "Epoch 43 - loss: 0.0014559755800291896\n",
      "Epoch 44 - loss: 0.00022012002591509372\n",
      "Epoch 44 - loss: 0.0012306805001571774\n",
      "Epoch 45 - loss: 0.0001860640331869945\n",
      "Epoch 45 - loss: 0.0010402309708297253\n",
      "Epoch 46 - loss: 0.0001572632318129763\n",
      "Epoch 46 - loss: 0.000879252387676388\n",
      "Epoch 47 - loss: 0.00013293120719026774\n",
      "Epoch 47 - loss: 0.0007432107231579721\n",
      "Epoch 48 - loss: 0.00011236962745897472\n",
      "Epoch 48 - loss: 0.0006281852838583291\n",
      "Epoch 49 - loss: 9.497415157966316e-05\n",
      "Epoch 49 - loss: 0.0005309681291691959\n",
      "Epoch 50 - loss: 8.028384036151692e-05\n",
      "Epoch 50 - loss: 0.0004488164559006691\n",
      "Epoch 51 - loss: 6.785178266000003e-05\n",
      "Epoch 51 - loss: 0.0003793685755226761\n",
      "Epoch 52 - loss: 5.735682134400122e-05\n",
      "Epoch 52 - loss: 0.0003206369001418352\n",
      "Epoch 53 - loss: 4.847989112022333e-05\n",
      "Epoch 53 - loss: 0.00027102857711724937\n",
      "Epoch 54 - loss: 4.097798955626786e-05\n",
      "Epoch 54 - loss: 0.00022907958191353828\n",
      "Epoch 55 - loss: 3.4635286283446476e-05\n",
      "Epoch 55 - loss: 0.00019365215848665684\n",
      "Epoch 56 - loss: 2.927310561062768e-05\n",
      "Epoch 56 - loss: 0.00016366429917979985\n",
      "Epoch 57 - loss: 2.4745137125137262e-05\n",
      "Epoch 57 - loss: 0.00013834709534421563\n",
      "Epoch 58 - loss: 2.0915564164170064e-05\n",
      "Epoch 58 - loss: 0.00011693756096065044\n",
      "Epoch 59 - loss: 1.7677715732133947e-05\n",
      "Epoch 59 - loss: 9.883875463856384e-05\n",
      "Epoch 60 - loss: 1.4941451809136197e-05\n",
      "Epoch 60 - loss: 8.354929741472006e-05\n",
      "Epoch 61 - loss: 1.2632175639737397e-05\n",
      "Epoch 61 - loss: 7.06207865732722e-05\n",
      "Epoch 62 - loss: 1.067955145117594e-05\n",
      "Epoch 62 - loss: 5.968664481770247e-05\n",
      "Epoch 63 - loss: 9.024104656418785e-06\n",
      "Epoch 63 - loss: 5.0451013521524146e-05\n",
      "Epoch 64 - loss: 7.626587830600329e-06\n",
      "Epoch 64 - loss: 4.264490780769847e-05\n",
      "Epoch 65 - loss: 6.448267868108815e-06\n",
      "Epoch 65 - loss: 3.6042027204530314e-05\n",
      "Epoch 66 - loss: 5.450259777717292e-06\n",
      "Epoch 66 - loss: 3.046322126465384e-05\n",
      "Epoch 67 - loss: 4.605218691722257e-06\n",
      "Epoch 67 - loss: 2.575330472609494e-05\n",
      "Epoch 68 - loss: 3.893226221407531e-06\n",
      "Epoch 68 - loss: 2.1764644770883024e-05\n",
      "Epoch 69 - loss: 3.289282403784455e-06\n",
      "Epoch 69 - loss: 1.8394443031866103e-05\n",
      "Epoch 70 - loss: 2.7809876428364078e-06\n",
      "Epoch 70 - loss: 1.5552641343674622e-05\n",
      "Epoch 71 - loss: 2.3493510070693446e-06\n",
      "Epoch 71 - loss: 1.314184828515863e-05\n",
      "Epoch 72 - loss: 1.986087909244816e-06\n",
      "Epoch 72 - loss: 1.1107782484032214e-05\n",
      "Epoch 73 - loss: 1.6792643009466701e-06\n",
      "Epoch 73 - loss: 9.387677891936619e-06\n",
      "Epoch 74 - loss: 1.4194553159541101e-06\n",
      "Epoch 74 - loss: 7.938256203487981e-06\n",
      "Epoch 75 - loss: 1.2004678637822508e-06\n",
      "Epoch 75 - loss: 6.7059663706459105e-06\n",
      "Epoch 76 - loss: 1.0140450967810466e-06\n",
      "Epoch 76 - loss: 5.668107860401506e-06\n",
      "Epoch 77 - loss: 8.566497058382083e-07\n",
      "Epoch 77 - loss: 4.791606443177443e-06\n",
      "Epoch 78 - loss: 7.246308655339817e-07\n",
      "Epoch 78 - loss: 4.049692051921738e-06\n",
      "Epoch 79 - loss: 6.123727303020132e-07\n",
      "Epoch 79 - loss: 3.424795067985542e-06\n",
      "Epoch 80 - loss: 5.17661419507931e-07\n",
      "Epoch 80 - loss: 2.8945726171514252e-06\n",
      "Epoch 81 - loss: 4.371816828552255e-07\n",
      "Epoch 81 - loss: 2.4483661036356352e-06\n",
      "Epoch 82 - loss: 3.698982311561849e-07\n",
      "Epoch 82 - loss: 2.068580442937673e-06\n",
      "Epoch 83 - loss: 3.1250428378371e-07\n",
      "Epoch 83 - loss: 1.746297698446142e-06\n",
      "Epoch 84 - loss: 2.6434750566295406e-07\n",
      "Epoch 84 - loss: 1.476559759794327e-06\n",
      "Epoch 85 - loss: 2.232949896097125e-07\n",
      "Epoch 85 - loss: 1.248082639904169e-06\n",
      "Epoch 86 - loss: 1.8880415098010417e-07\n",
      "Epoch 86 - loss: 1.0553900438026176e-06\n",
      "Epoch 87 - loss: 1.5946149289902678e-07\n",
      "Epoch 87 - loss: 8.920169420889579e-07\n",
      "Epoch 88 - loss: 1.3507127505363314e-07\n",
      "Epoch 88 - loss: 7.536376074313011e-07\n",
      "Epoch 89 - loss: 1.1388215170882177e-07\n",
      "Epoch 89 - loss: 6.370464689098299e-07\n",
      "Epoch 90 - loss: 9.642403853149517e-08\n",
      "Epoch 90 - loss: 5.388616841628391e-07\n",
      "Epoch 91 - loss: 8.150567509801476e-08\n",
      "Epoch 91 - loss: 4.5553588279290125e-07\n",
      "Epoch 92 - loss: 6.865631263508476e-08\n",
      "Epoch 92 - loss: 3.848681444651447e-07\n",
      "Epoch 93 - loss: 5.817416237619e-08\n",
      "Epoch 93 - loss: 3.255117917433381e-07\n",
      "Epoch 94 - loss: 4.9250974853976004e-08\n",
      "Epoch 94 - loss: 2.754923116299324e-07\n",
      "Epoch 95 - loss: 4.165343625572859e-08\n",
      "Epoch 95 - loss: 2.3252414393937215e-07\n",
      "Epoch 96 - loss: 3.5121974661933564e-08\n",
      "Epoch 96 - loss: 1.9673946383136354e-07\n",
      "Epoch 97 - loss: 2.9806340506866036e-08\n",
      "Epoch 97 - loss: 1.6611890885087632e-07\n",
      "Epoch 98 - loss: 2.51226115466352e-08\n",
      "Epoch 98 - loss: 1.4050753804895066e-07\n",
      "Epoch 99 - loss: 2.1242479775196443e-08\n",
      "Epoch 99 - loss: 1.1880698735922124e-07\n"
     ]
    }
   ],
   "source": [
    "# Student name: Jiayan Dong\n",
    "# PID: A16593051\n",
    "# Date: 10/9/2022\n",
    "\n",
    "### Training with manually updating W with \"Backward\" ###\n",
    "\n",
    "from tkinter import YView\n",
    "import torch\n",
    "#from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "\n",
    "minibatch_size = 3\n",
    "data = [(1.0,2.1,3.0), (2.0, 3.5, 6.0), (3.0, 3.0, 9.0), (4.0, 2.1, 12.0), (5.0, 7.2, 15.0), (6.0, 10.1, 18.0)]\n",
    "data = torch.tensor(data, dtype=torch.float)\n",
    "trainX = data[:,:-1].reshape(-1, minibatch_size, data.shape[1] - 1)\n",
    "trainY = data[:,-1].reshape(-1, minibatch_size, 1)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(2,1,bias=False)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "print(net)\n",
    "\n",
    "net.fc1.weight = torch.nn.Parameter(torch.tensor([[1., -1.]], requires_grad=True))\n",
    "print(list(net.parameters()))\n",
    "\n",
    "#input = torch.randn(1)\n",
    "#out = net(input)\n",
    "\n",
    "#def criterion(out, label):\n",
    "#    return (label - out)**2\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.5)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.005)\n",
    "\n",
    "for epoch in range(100):   \n",
    "    for X, Y in zip(trainX, trainY):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(X)\n",
    "        loss = criterion(outputs, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch {} - loss: {}\".format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77f00a67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when x = tensor([1.0000, 2.1000]), y = tensor([3.0001], grad_fn=<SqueezeBackward3>), target = 3.0\n",
      "when x = tensor([2.0000, 3.5000]), y = tensor([6.0001], grad_fn=<SqueezeBackward3>), target = 6.0\n",
      "when x = tensor([3., 3.]), y = tensor([8.9998], grad_fn=<SqueezeBackward3>), target = 9.0\n",
      "when x = tensor([4.0000, 2.1000]), y = tensor([11.9995], grad_fn=<SqueezeBackward3>), target = 12.0\n",
      "when x = tensor([5.0000, 7.2000]), y = tensor([15.0000], grad_fn=<SqueezeBackward3>), target = 15.0\n",
      "when x = tensor([ 6.0000, 10.1000]), y = tensor([18.0002], grad_fn=<SqueezeBackward3>), target = 18.0\n"
     ]
    }
   ],
   "source": [
    "for current_data in data:\n",
    "    out = net(current_data[:-1])  \n",
    "    print(\"when x = {}, y = {}, target = {}\".format(current_data[:-1], out, current_data[-1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
